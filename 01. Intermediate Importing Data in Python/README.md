# Intermediate Importing Data in Python

This repository contains materials and exercises from DataCamp's "Intermediate Importing Data in Python" course, part of the "Data Scientist in Python" track.

## Course Content

The course is divided into three main sections:

1. **Importing data from the Internet**

   - Working with flat files from the web
   - HTTP requests using urllib and requests
   - Web scraping with BeautifulSoup
   - Extracting HTML elements and text

2. **Interacting with APIs to import data from the web**

   - Working with APIs and JSON data
   - Authentication methods for APIs
   - Parsing and working with API responses

3. **Diving deep into the Twitter API**
   - Twitter API authentication
   - Extracting tweet data
   - Working with Twitter streams
   - Analysis of Twitter data

## Datasets

The repository includes several datasets used throughout the exercises:

- `winequality-red.csv` - Contains data about the physiochemical properties of red wine
- `latitude.xls` - Excel spreadsheet with latitude data
- `tweets.txt` - Sample Twitter data for analysis

## Requirements

The notebooks use the following Python libraries:

- pandas
- matplotlib
- urllib
- requests
- BeautifulSoup
- json
- tweepy (for Twitter API)

## Usage

Open the Jupyter notebooks (.ipynb files) in order to follow the course content:

1. Start with "01. Importing data from the Internet.ipynb"
2. Continue with "02. Interacting with APIs to import data from the web.ipynb"
3. Finish with "03. Diving deep into the Twitter API.ipynb"

## Notes

These notebooks contain both exercises and solutions from the DataCamp course. They serve as a reference for importing data in Python using various methods and sources.

Last Updated: May 24, 2025
