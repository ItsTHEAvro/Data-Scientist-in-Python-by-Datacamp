## Machine learning mistakes

* **Starting ML without Proper Preparation ("Machine learning first"):**
    * ML should not be the initial data initiative.
    * Requires foundational elements like clean, readily available data and sufficient descriptive analysis to understand the problem and identify ML opportunities.
    * Avoid pursuing ML just because it's a trend.

* **Insufficient or Poor Quality Data ("Not enough data"):**
    * "Garbage in, garbage out" principle: Poor data leads to poor ML output.
    * Crucial to ensure data availability and quality before starting ML projects.

* **Poor Target Variable Definition:**
    * Clearly defining the business problem and the target variable is critical (e.g., fraud, churn, purchase).
    * Need to determine if the target variable is observable or needs to be defined (e.g., contractual vs. non-contractual churn).
    * In-depth analysis and business team involvement (field expertise) are essential for defining the target variable, especially for unobserved outcomes. This is a highly critical step.

* **Under-investing in Feature Selection:**
    * **Inferential Models:** Focus on variables that can be controlled and influenced by the business (levers like price, delivery terms), requiring business expertise.
    * **Predictive Models:** An iterative process. Start with readily available data and a simple model. If promising, test it. Then, incrementally add new features from less accessible sources and continue testing.

* **Long Model Development Leading to Late Testing and No Impact:**
    * Avoid striving for model perfection at the expense of timely market testing.
    * Once a decent baseline model is built, test it quickly to see if it's actionable (e.g., via A/B testing).
    * Set target due dates for market testing to ensure the ML team doesn't spend excessive time on incremental improvements without real-world validation.

## Communication Management

* **Establish Working Groups & Recurring Meetings:**
    * Dedicate a business point of contact.
    * Hold regular progress meetings (weekly to monthly).
    * **Key Meeting Topics:** Define business requirements, review models/products, identify inference/prediction use cases, discuss baseline model results, outline market testing strategy, and talk about potential production systems.

* **Define Clear Business Requirements:**
    * **Identify Business Situation:** Understand the current problem (e.g., rising churn rate).
    * **Assess Opportunity Size:** Estimate the potential improvement with ML (e.g., target churn reduction level).
    * **Determine Business Actions:** Define what actions can be taken based on ML insights (e.g., strategies for at-risk customers).

* **Define Actionable Machine Learning Products:**
    * Translate ML models into tangible products the business can use.
    * **Examples:**
        * **Churn Prediction Model:** Products could be a quarterly churn driver outlook and daily customer segmentation (lost, at-risk, no-risk) for targeted campaigns.
        * **Fraud Prediction Model:** Products could be monthly updates on strong fraud indicators, a real-time list of high-risk transactions for manual review, and a list of medium-risk transactions for further data requests.

* **Establish Model Performance Tolerance & Improvement Metrics:**
    * Recognize that all models are approximations and will have errors.
    * **Classification:** Determine which misclassification type is more costly (e.g., in fraud, misclassifying a good transaction as fraud is often preferred over missing actual fraud).
    * **Regression:** Assess the business impact of prediction errors (e.g., in demand prediction, errors lead to wasted resources or idle inventory). Decide on acceptable error levels upfront.

* **Prioritize Early Market Testing:**
    * Identify potential market interventions and experiments early on.
    * This tests the model's readiness for production based on real-world results.

* **Evaluate for Machine Learning in Production:**
    * After market tests, assess if desired positive improvements are achieved consistently and stably over time.
    * If successful, proceed to discussions on identifying production systems and resourcing the implementation of ML models.

## Machine Learning in Production

* **Definition:** Production systems are software or applications integral to business operations, sometimes being the business itself. ML models are deployed within these systems to enhance customer and product experiences.

* **Examples of Production Systems with ML:**
    * **Customer Relationship Management (CRM):** Predicts customer churn, triggering automated retention campaigns (e.g., emails).
    * **Fraud Detection System:** Analyzes transaction data points in real-time, uses ML to predict and automatically block likely fraudulent transactions, flagging them for manual review.
    * **Online Banking Platform:** Employs multiple ML models, such as recommender engines to personalize website experience by showing relevant products based on predicted customer interest.
    * **Autonomous Cars:** ML is core to self-driving software, used for functions like collision avoidance by scanning surroundings and initiating evasive actions (braking, steering).

* **Staffing for Production ML:**
    * Deploying ML models into production is a software engineering process.
    * **Prototype models:** Built by Data Scientists and ML Engineers.
    * **Production integration:** Done by Software Engineers, Data Engineers, and Infrastructure Owners.
    * This distinction is important as production deployment can be significantly more expensive and requires upfront resource planning.

* **Launch, Tracking, and Feedback Process:**
    * **Preparation:** Plan obsessively and prepare for potential issues ("Murphy's Law").
    * **Initial Launch (Small Scale):** Deploy to a subset of customers first.
    * **Performance Tracking:** Monitor model results for a period to ensure they are as expected and consistent.
    * **System Monitoring:** Track the system's overall performance, stability, impact of ML integration, and any changes in customer feedback.
    * **Iterative Scaling:** If the model performs well and the system is stable, gradually increase exposure to more customers. Repeat tracking and monitoring with each scaling step until full deployment.
    * **Iterative Improvements & New Launches:** Each new model version or improvement should follow a similar phased launch process to ensure system performance and desired business outcomes are not negatively affected. Even high-performing prototypes might not be actionable if they compromise business results.